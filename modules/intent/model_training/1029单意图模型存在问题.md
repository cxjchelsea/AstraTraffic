# 主要问题

1. **类别混淆：健康咨询 ←→ 其他任务类**
   - 现象：健康咨询 **P=0.81**（误报偏多），R=0.91（较高）。
   - 成因：语义覆盖过宽；与药品服务、报告解读、就医转诊等边界模糊；样本占比大导致模型偏好预测为该类。
2. **“闲聊其他”漏检（Recall 低）**
   - 现象：闲聊其他 **R=0.522**（漏判多），F1=0.637。
   - 成因：样本量较少、分布发散；标注边界不清；与任务型问句混淆（如寒暄+咨询）。
3. **数据与标注层面**
   - 类别不平衡与“长尾类”支持度较低。
   - 可能存在跨类语义重叠、弱标注噪声（weak_primary）未清洗。
   - 训练/推理时 Tokenizer 配置不一致风险（已保存 tokenizer 文件，但需强约束加载）。
4. **评估与监控**
   - 尚未沉淀**混淆矩阵**与**错误样例类别学**（error taxonomy），难以精准对症。
   - 线上无“拒识/兜底”策略，低置信度样本仍被强判为头部类。

# 改进方向

A. **数据治理优先**：边界再定义 + 难例采样 + 类别平衡
B. **训练策略增强**：对比学习/难例挖掘/损失函数调优
C. **推理与后处理**：两阶段路由 + 置信度阈值/拒识 + 规则微校正
D. **评估与回路**：可解释监控 + 迭代闭环（主动学习）

# 改进方法

## 3.1 数据与标注

1. **边界重定义（标准清单）**
   - 健康咨询：涉及“症状/诊断/治疗/建议”的问句才归入；凡涉及“报告/药名/挂号/转诊/系统操作”关键词→路由到对应类。
   - 闲聊其他：问候/感谢/再见/无任务信息/情绪表达，不包含医疗问题的问句。
   - 产出：一页 A4「**正负样例对照表**」+ **关键词参考表**（如“报告/化验/药/挂号/系统/登录”等）。
2. **难例采样 & 对比式标注**
   - 从健康咨询的误报样本中，采出与“药品服务/报告解读/就医转诊”相似句做**成对对比**（正负示例成对）。
   - 从闲聊漏检样本中，补充模板句：`你好/谢谢/在吗/晚安/再见/辛苦了` + 情绪句。
3. **类平衡与数据清洗**
   - **下采样**健康咨询（或**上采样**其他类），目标：每类训练样本差距 ≤ 2x。
   - 清理弱标注冲突/噪声（weak_primary 与强标注不一致的样本剔除或低权重）。
4. **数据增强（轻量）**
   - 同义替换、礼貌前后缀（“您好”“麻烦”“可以吗”）、口语/书面体互换；对“闲聊”增加模版化多样性。

## 3.2 训练与损失

1. **难例挖掘（Hard Negative Mining）**
   - 每个 batch 注入与“健康咨询”最易混淆的负类样本（药品服务/报告解读/就医转诊）。
2. **对比学习 / Margin 损失（可选）**
   - 在 CLS 表征上加入对比损失（同类拉近、异类拉远），或使用 **Label Smoothing**（减少过度自信）。
3. **损失函数与采样权重**
   - 尝试 **class weights** 或 **Focal Loss(γ=1~2)**，抑制头部类（健康咨询）的易例；提升长尾/难类学习。
4. **阈值/校准（post-hoc）**
   - 用温度缩放/Platt scaling 做**概率校准**，减少误报（有助于“健康咨询”精确率）。

## 3.3 推理与后处理

1. **两阶段路由（强烈推荐）**
   - Stage-1：**任务型 vs 闲聊二分类**（binary），高召回捕获闲聊。
   - Stage-2：对任务型再做 10 类细分（当前主模型）。
   - 效果：显著提升“闲聊其他”的召回，降低其被错分为健康咨询。
2. **置信度阈值 & 拒识兜底**
   - Softmax 最大概率 < τ（如 0.55）→ 输出“低置信度，转人工/兜底提示”；对健康咨询单类可设置**更高阈值**抑制误报。
   - 结合 **Top-2 距离**（p1 − p2 < δ 判为不确定）减少边界样本误判。
3. **轻规则微校正**
   - 出现“报告/检验/化验/影像”→ 报告解读优先；
   - 出现“挂号/转诊/就医/医院/医生推荐”→ 就医转诊优先；
   - 出现“登录/充值/绑定/更新/版本/系统/卡顿”→ 系统操作优先。
   - 规则仅在**低置信度**或**Top-2 接近**时触发，避免过拟合规则。

## 3.4 评估与监控

1. **固定输出：混淆矩阵 + 错误样例导出**
   - 每次评测自动保存 `confusion_matrix.xlsx` 与误判样例（预测→真值、概率、文本）。
2. **分桶监控**
   - 按文本长度、礼貌前缀、是否含问号、是否含关键实体做子集 F1，定位脆弱切片。
3. **线上监控与主动学习**
   - 收集低置信度/频繁重试/用户纠错样本，进入标注闭环（每周小批量增量微调）