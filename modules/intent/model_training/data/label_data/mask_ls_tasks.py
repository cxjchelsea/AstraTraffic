#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
mask_ls_tasks.py â€”â€” äº§å‡ºä¸æ–¹æ¡ˆ A å®Œå…¨åŒ¹é…çš„ Label Studio æ–‡ä»¶

ç‰¹æ€§ï¼š
- è¾“å‡ºè‹±æ–‡é”® dataï¼štext / weak_primary / weak_secondary / weak_confidence / weak_reason
- è¾“å‡ºçš„ ls_config.xml ä½¿ç”¨ $text / $weak_primary / $weak_secondary / $weak_confidence / $weak_reason
- è¿œç«¯æ¨ç†ï¼ˆOpenAI å…¼å®¹æ¥å£ï¼šOllama / vLLM / å…¶å®ƒï¼‰ï¼Œå¹¶å‘+æ–­ç‚¹ç»­è·‘
- åç±»ä¸­æ–‡æ„å›¾ï¼ˆä¸»æ„å›¾å¿…é€‰ã€æ¬¡æ„å›¾å¯ç©ºï¼‰
"""

from __future__ import annotations
import json
import os
import re
import time
from typing import Any, Iterable, List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

from datasets import load_dataset
from openai import OpenAI
from openai._exceptions import APIStatusError, RateLimitError, APIConnectionError

# --- æ”¾åœ¨æ–‡ä»¶å¾ˆå‰é¢ï¼Œé¿å…è¢«åç»­å¯¼å…¥è¦†ç›– ---
import os
os.environ["NO_PROXY"] = "127.0.0.1,localhost"
os.environ["no_proxy"] = "127.0.0.1,localhost"

# =============== æ¨ç†æœåŠ¡é…ç½®ï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰ =================
# ğŸ‘‰ å¦‚æœæ˜¯ Ollamaï¼šæŠŠ OPENAI_BASE æ”¹æˆ http://<ip>:11434/v1 ï¼ŒREMOTE_MODEL æ”¹æˆ "qwen2.5:14b"
# OPENAI_BASE = "http://127.0.0.1:11434/v1"   # â† ä½ çš„è¿œç«¯æœåŠ¡åœ°å€ï¼ˆOllama / vLLMï¼‰
OPENAI_BASE = "http://192.168.3.47:11434/v1"   # â† ä½ çš„è¿œç«¯æœåŠ¡åœ°å€ï¼ˆOllama / vLLMï¼‰
OPENAI_API_KEY = "EMPTY"                       # Ollama é»˜è®¤å¯ä»»æ„å ä½ï¼›vLLM å¦‚é…ç½®é‰´æƒåˆ™å¡«çœŸå®key
REMOTE_MODEL   = "qwen2.5:14b"                 # ä¸è¿œç«¯æœåŠ¡åŠ è½½çš„æ¨¡å‹åä¸€è‡´
MAX_TOKENS     = 32                           # åˆ†ç±»è¾“å‡º JSONï¼Œ64 è¶³å¤Ÿï¼›æƒ³æ›´å¿«å¯æ”¹ 32
TEMPERATURE    = 0.0                           # åˆ†ç±»ç”¨è´ªå¿ƒè§£ç æ›´ç¨³
CONCURRENCY    = 8                             # å¹¶å‘çº¿ç¨‹æ•°ï¼ŒæŒ‰è¿œç«¯è´Ÿè½½è°ƒæ•´
TIMEOUT_SEC    = 60                            # å•è¯·æ±‚è¶…æ—¶ï¼ˆå¯æŒ‰éœ€è°ƒæ•´ï¼‰
# ========================================================

# =============== æ•°æ®ä¸è¾“å‡º =============================
DATASET_NAME   = "FreedomIntelligence/huatuo26M-testdatasets"
SPLIT: Optional[str] = None        # None=auto(train>test>validation)
QUESTION_FIELD = "questions"
MAX_SAMPLES: Optional[int] = 10  # å…ˆå°æ ·æœ¬éªŒè¯å¯è®¾ 200ï¼›å…¨é‡ç”¨ None
# # =============== CSV å…¼å®¹é…ç½®ï¼ˆæ–°å¢ï¼‰ =====================
# DATASET_NAME   = "./label_data/cMedQA2/question.csv"
# # å¦‚æœ DATASET_NAME æ˜¯ *.csvï¼Œåˆ™æŒ‰ CSV è¯»å–
CSV_DELIMITER: Optional[str] = None   # ä¾‹ï¼š"," æˆ– "\t"ï¼›None è¡¨ç¤ºè‡ªåŠ¨
# SPLIT: Optional[str] = None        # None=auto(train>test>validation)
# # å½“ QUESTION_FIELD ä¸ºç©ºæˆ–ä¸åœ¨åˆ—é‡Œæ—¶ï¼ŒæŒ‰æ­¤å€™é€‰åˆ—è¡¨è‡ªåŠ¨æ¢æµ‹
# QUESTION_FIELD = "content"
# MAX_SAMPLES: Optional[int] = None  # å…ˆå°æ ·æœ¬éªŒè¯å¯è®¾ 200ï¼›å…¨é‡ç”¨ None
# =========================================================
OUT_JSON   = "test_ls_tasks.json"       # å¯¼å…¥ Label Studio çš„æ•°ç»„ JSONï¼ˆå¸¦ annotationsï¼‰
OUT_JSONL  = "ls_tasks.jsonl"      # æ–­ç‚¹ç»­è·‘å¢é‡æ–‡ä»¶
OUT_CONFIG = "ls_config.xml"       # ä¸æ–¹æ¡ˆ A åŒ¹é…çš„é…ç½®
# ========================================================

# åç±»ä¸­æ–‡æ„å›¾
INTENTS_CN = [
    "å¥åº·å’¨è¯¢",
    "è¯å“æœåŠ¡",
    "æŠ¥å‘Šè§£è¯»",
    "å°±åŒ»è½¬è¯Š",
    "ç´§æ€¥æ±‚åŠ©",
    "ç³»ç»Ÿæ“ä½œ",
    "æƒ…æ„Ÿæ”¯æŒ",
    "å®¶åº­ç®¡ç†",
    "ç¯å¢ƒå¥åº·",
    "é—²èŠå…¶ä»–",
]

# è®©æ¨¡å‹ä¸¥æ ¼è¾“å‡º JSON çš„ç³»ç»Ÿæç¤º
LLM_SYSTEM_PROMPT_CN = f"""ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡åŒ»ç–—æ„å›¾åˆ†ç±»åŠ©ç†ã€‚è¯·åŸºäºç”¨æˆ·ä¸€å¥è¯ï¼Œåœ¨ä¸‹åˆ—åä¸ªä¸­æ–‡æ„å›¾ä¸­åˆ¤æ–­ï¼š
{', '.join(INTENTS_CN)}

è¦æ±‚ï¼š
1) primary å¿…é¡»ä¸”ä»…èƒ½ä»ä¸Šé¢åç±»ä¸­é€‰ä¸€ä¸ªï¼ˆä¸­æ–‡æ ‡ç­¾ï¼Œéœ€å®Œå…¨åŒ¹é…ï¼‰ã€‚
2) secondary ä¸ºä¸Šé¢åç±»ä¸­çš„è‹¥å¹²ä¸ªï¼ˆå¯ä¸ºç©ºæ•°ç»„ï¼‰ï¼ŒåŒæ ·å¿…é¡»æ˜¯ä¸­æ–‡æ ‡ç­¾ã€‚
3) è¾“å‡ºä¸¥æ ¼ä¸º JSONï¼Œå­—æ®µï¼šprimary(å­—ç¬¦ä¸²,ä¸­æ–‡)ã€secondary(å­—ç¬¦ä¸²æ•°ç»„,ä¸­æ–‡)ã€confidence(0~1)ã€reason(ä¸­æ–‡,ä¸è¶…è¿‡50å­—)ã€‚
4) åªè¾“å‡º JSONï¼Œä¸è¦å¤šä½™æ–‡æœ¬ã€‚
"""
USER_PROMPT_CN = "ç”¨æˆ·é—®é¢˜ï¼š{q}\nè¯·æŒ‰è¦æ±‚è¾“å‡º JSONã€‚"
JSON_REGEX = re.compile(r"\{.*\}", re.S)


# ----------------- å·¥å…·æ–¹æ³• -----------------
def load_input_dataset() -> Tuple[Dict[str, Any], str]:
    """
    è¿”å› (DatasetDict, split_name)
    - è‹¥ DATASET_NAME æ˜¯ CSV è·¯å¾„ï¼šç”¨ datasets.load_dataset('csv', ...)
    - å¦åˆ™ï¼šæŒ‰åŸé€»è¾‘ load_dataset(DATASET_NAME)
    """
    if os.path.isfile(DATASET_NAME) and DATASET_NAME.lower().endswith(".csv"):
        kwargs = {}
        if CSV_DELIMITER:
            kwargs["delimiter"] = CSV_DELIMITER
        ds_dict = load_dataset("csv", data_files=DATASET_NAME, **kwargs)
        # load_dataset('csv') è¿”å›çš„ split åä¸€èˆ¬æ˜¯ 'train'
        split = pick_split(ds_dict)
        return ds_dict, split
    else:
        ds_dict = load_dataset(DATASET_NAME)
        split = SPLIT or pick_split(ds_dict)
        return ds_dict, split


def resolve_question_field(dset) -> str:
    """
    ç¡®å®šç”¨äºæŠ½é—®å¥çš„åˆ—åï¼š
    1) å¦‚æœ QUESTION_FIELD éç©ºä¸”å­˜åœ¨ï¼Œç›´æ¥ç”¨
    2) å¦åˆ™åœ¨å¸¸è§åˆ—åé‡Œè‡ªåŠ¨æ¢æµ‹
    3) å¦åˆ™é€‰ç¬¬ä¸€ä¸ª string ç±»å‹çš„åˆ—
    """
    cols = list(dset.features.keys())
    # 1) ç›´æ¥å‘½åä¼˜å…ˆ
    if QUESTION_FIELD and QUESTION_FIELD in cols:
        return QUESTION_FIELD

    # 2) å¸¸è§å€™é€‰
    for k in QUESTION_FIELD:
        if k in cols:
            return k

    # 3) æ‰¾ç¬¬ä¸€ä¸ª string åˆ—
    try:
        from datasets import Value
        for k, v in dset.features.items():
            if isinstance(v, Value) and v.dtype in ("string", "large_string"):
                return k
    except Exception:
        pass

    # å…œåº•ï¼šç”¨ç¬¬ä¸€ä¸ªåˆ—å
    return cols[0] if cols else QUESTION_FIELD or "text"


def pick_split(ds_dict) -> str:
    keys = list(ds_dict.keys())
    for k in ("train", "test", "validation"):
        if k in keys:
            return k
    return keys[0]


def iter_questions(val: Any) -> Iterable[str]:
    """ä» questions å­—æ®µæŠ½é—®å¥ï¼šå…¼å®¹ str / list[str] / list[dict] / dict"""
    keys = ("question", "instruction", "input", "query", "prompt")
    if val is None:
        return []
    if isinstance(val, str):
        s = val.strip()
        return [s] if s else []
    if isinstance(val, list):
        out: List[str] = []
        for it in val:
            if isinstance(it, str):
                s = it.strip()
                if s:
                    out.append(s)
            elif isinstance(it, dict):
                for k in keys:
                    v = it.get(k)
                    if isinstance(v, str) and v.strip():
                        out.append(v.strip())
                        break
        return out
    if isinstance(val, dict):
        for k in keys:
            v = val.get(k)
            if isinstance(v, str) and v.strip():
                return [v.strip()]
    return []


def build_ls_config_xml() -> str:
    """Label Studio é…ç½®ï¼ˆä¸»æ„å›¾å•é€‰å¿…é€‰ + æ¬¡æ„å›¾å¤šé€‰å¯ç©ºï¼‰â€”â€”ä¸è‹±æ–‡é”®å¯¹é½"""
    choices_xml = "\n    ".join(f'<Choice value="{v}">{v}</Choice>' for v in INTENTS_CN)
    return f"""<View>
  <!-- å¾…æ ‡æ³¨æ–‡æœ¬ï¼ˆè‹±æ–‡é”® $textï¼‰ -->
  <Text name="text" value="$text" />

  <!-- ä¸»æ„å›¾ï¼šå¿…é€‰Â·å•é€‰ -->
  <Header value="è¯·é€‰æ‹©ã€ä¸»æ„å›¾ã€‘ï¼ˆå¿…é€‰Â·å•é€‰ï¼‰" />
  <Choices name="primary" toName="text" choice="single" required="true" showInLine="true">
    {choices_xml}
  </Choices>

  <!-- æ¬¡æ„å›¾ï¼šå¯å¤šé€‰Â·å¯ç•™ç©º -->
  <Header value="å¯é€‰ï¼šè¯·é€‰æ‹©ã€æ¬¡æ„å›¾ã€‘ï¼ˆå¯å¤šé€‰Â·å¯ç•™ç©ºï¼‰" />
  <Choices name="secondary" toName="text" choice="multiple" showInLine="true">
    {choices_xml}
  </Choices>

  <!-- é¢„æ ‡æ³¨ä¿¡æ¯ï¼ˆä»…å±•ç¤ºï¼Œä¸å‚ä¸ toName å¼•ç”¨ï¼‰ -->
  <Header value="â€”â€” é¢„æ ‡æ³¨ï¼ˆä»…å‚è€ƒï¼‰ â€”â€”" />
  <Text name="weak1" value="å¼±ä¸»æ„å›¾ï¼š$weak_primary" />
  <Text name="weak2" value="å¼±æ¬¡æ„å›¾ï¼š$weak_secondary" />
  <Text name="weak3" value="ç½®ä¿¡åº¦ï¼š$weak_confidence" />
  <Text name="weak4" value="ç†ç”±ï¼š$weak_reason" />
</View>"""


def safe_json_extract(text: str) -> Dict[str, Any]:
    """å°½åŠ›ä» text ä¸­æå– JSONï¼›å¤±è´¥åˆ™è¿”å›å…œåº•ç»“æ„ã€‚"""
    m = JSON_REGEX.search(text)
    if m:
        try:
            return json.loads(m.group(0))
        except Exception:
            pass
    braces = re.findall(r"\{.*\}", text, re.S)
    if braces:
        try:
            return json.loads(braces[-1])
        except Exception:
            pass
    return {"primary": "é—²èŠå…¶ä»–", "secondary": [], "confidence": 0.5, "reason": "è§£æå¤±è´¥å…œåº•"}


def make_ls_result(primary: str, secondary: List[str]) -> List[Dict[str, Any]]:
    res = []
    if primary:
        res.append({
            "from_name": "primary",
            "to_name": "text",
            "type": "choices",
            "value": {"choices": [primary]},
        })
    if secondary:
        res.append({
            "from_name": "secondary",
            "to_name": "text",
            "type": "choices",
            "value": {"choices": secondary},
        })
    return res


def load_done_set(jsonl_path: str) -> set:
    """ä» JSONL é‡ŒåŠ è½½å·²å®Œæˆæ–‡æœ¬é›†åˆï¼ˆæ–­ç‚¹ç»­è·‘ï¼‰"""
    done = set()
    if os.path.isfile(jsonl_path):
        with open(jsonl_path, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    obj = json.loads(line)
                    txt = obj.get("data", {}).get("text")   # æ³¨æ„è‹±æ–‡é”®
                    if txt:
                        done.add(txt)
                except Exception:
                    continue
    return done


# ----------------- è¿œç¨‹æ¨ç†å®¢æˆ·ç«¯ -----------------
client = OpenAI(
    base_url=OPENAI_BASE,
    api_key=OPENAI_API_KEY,
    timeout=TIMEOUT_SEC,
)

def classify_remote(q: str, retry: int = 3, backoff: float = 1.5) -> Tuple[str, List[str], float, str]:
    """
    è°ƒç”¨è¿œç«¯ OpenAI å…¼å®¹æ¥å£ï¼ˆChat Completionsï¼‰åšå•æ¡åˆ†ç±»ã€‚
    è¿”å›ï¼š(primary, secondary[], confidence, reason)
    """
    system = {"role": "system", "content": LLM_SYSTEM_PROMPT_CN}
    user   = {"role": "user",   "content": USER_PROMPT_CN.format(q=q)}
    last_err = None
    for k in range(retry):
        try:
            rsp = client.chat.completions.create(
                model=REMOTE_MODEL,
                messages=[system, user],
                temperature=TEMPERATURE,
                max_tokens=MAX_TOKENS,
                stream=False,
            )
            text = rsp.choices[0].message.content or ""
            data = safe_json_extract(text)

            primary = str(data.get("primary", "")).strip()
            secondary = data.get("secondary") or []
            if isinstance(secondary, str):
                secondary = [secondary]
            secondary = [s for s in (str(i).strip() for i in secondary) if s]

            # çº¦æŸåˆ°åç±»
            if primary not in INTENTS_CN:
                primary = "é—²èŠå…¶ä»–"
            secondary = [s for s in secondary if s in INTENTS_CN]

            try:
                conf = float(data.get("confidence", 0.7))
            except Exception:
                conf = 0.7
            reason = str(data.get("reason", "")).strip()[:100]
            return (primary, secondary, max(0.0, min(1.0, conf)), reason)
        except (APIStatusError, RateLimitError, APIConnectionError, TimeoutError) as e:
            last_err = e
            time.sleep((k + 1) * backoff)
        except Exception as e:
            last_err = e
            time.sleep((k + 1) * backoff)
    # æœ€ç»ˆå…œåº•
    return ("é—²èŠå…¶ä»–", [], 0.5, f"è¿œç«¯é”™è¯¯ï¼š{last_err}"[:100])


# ----------------- ä¸»æµç¨‹ -----------------
def main():
    print(f"ğŸ“¦ Loading dataset: {DATASET_NAME}")
    ds_dict, split = load_input_dataset()
    dset = ds_dict[split]
    print(f"âœ… Using split: {split}, rows={len(dset)}; remote_model={REMOTE_MODEL}")

    # è§£æé—®å¥åˆ—åï¼ˆæ”¯æŒ CSV è‡ªåŠ¨æ¢æµ‹ï¼‰
    q_field = resolve_question_field(dset)
    if QUESTION_FIELD and QUESTION_FIELD != q_field:
        print(f"âš ï¸ æŒ‡å®šçš„ QUESTION_FIELD='{QUESTION_FIELD}' ä¸åœ¨æ•°æ®åˆ—ä¸­ï¼Œå°†ä½¿ç”¨è‡ªåŠ¨è¯†åˆ«åˆ— '{q_field}'")
    else:
        print(f"ğŸ§­ Using question field: '{q_field}'")

    # æŠ½é—®å¥ + å»é‡
    seen = set()
    questions: List[str] = []
    for rec in dset:
        # å…¼å®¹ None / ç©ºç™½
        val = rec.get(q_field, None)
        for q in iter_questions(val):
            if q and q not in seen:
                seen.add(q)
                questions.append(q)
        if MAX_SAMPLES and len(questions) >= MAX_SAMPLES:
            break

    if not questions:
        raise RuntimeError(f"æœªä»åˆ— '{q_field}' æŠ½å–åˆ°é—®å¥ã€‚è¯·æ£€æŸ¥ CSV çš„åˆ—åæˆ–å†…å®¹ã€‚")
    print(f"ğŸ“ Extracted questions: {len(questions)}")

    total = len(questions)
    print(f"ğŸ“ Extracted questions: {total}")

    # æ–­ç‚¹ç»­è·‘ï¼šåŠ è½½å·²å®Œæˆ
    done = load_done_set(OUT_JSONL)
    if done:
        print(f"ğŸ” æ–­ç‚¹ç»­è·‘ï¼šæ£€æµ‹åˆ°å·²å®Œæˆ {len(done)} æ¡ï¼Œå°†è·³è¿‡è¿™äº›æ ·æœ¬ã€‚")

    # æ‰“å¼€ JSONL ä»¥ä¾¿å¢é‡å†™
    jsonl_f = open(OUT_JSONL, "a", encoding="utf-8")

    processed = 0
    start_time = time.time()

    # å¹¶å‘æ‰§è¡Œï¼šè·³è¿‡å·²å®Œæˆçš„ï¼Œåˆ†å‘åˆ°çº¿ç¨‹æ± 
    to_process = [q for q in questions if q not in done]
    n = len(to_process)
    print(f"ğŸš€ Start remote inference: {n} to process, concurrency={CONCURRENCY}")
    buf_tasks: List[Dict[str, Any]] = []

    with ThreadPoolExecutor(max_workers=CONCURRENCY) as ex:
        fut2q = {ex.submit(classify_remote, q): q for q in to_process}
        for fut in as_completed(fut2q):
            q = fut2q[fut]
            primary, secondary, conf, reason = fut.result()

            data = {
                # è‹±æ–‡é”® â€”â€” ä¸æ–¹æ¡ˆ A çš„ XML å¯¹é½
                "text": q,
                "weak_primary": primary,
                "weak_secondary": "ã€".join(secondary) if secondary else "",
                "weak_confidence": float(conf),
                "weak_reason": reason,
            }
            task: Dict[str, Any] = {"data": data}
            task["annotations"] = [{
                "result": make_ls_result(primary, secondary),
                "was_cancelled": False,
                "ground_truth": False,
            }]

            # æ–­ç‚¹ç»­è·‘ï¼šå¢é‡å†™å…¥
            jsonl_f.write(json.dumps(task, ensure_ascii=False) + "\n")
            jsonl_f.flush()

            buf_tasks.append(task)
            processed += 1

            if processed % 50 == 0:
                elapsed = time.time() - start_time
                speed = processed / max(1e-9, elapsed)
                print(f"ğŸ§© Prelabelled {processed}/{n} | {speed:.2f} samples/s | elapsed {elapsed/60:.1f} min")

    jsonl_f.close()

    # æ±‡æ€» JSONL â†’ JSONï¼ˆLabel Studio å¯¼å…¥ï¼‰
    tasks: List[Dict[str, Any]] = []
    with open(OUT_JSONL, "r", encoding="utf-8") as f:
        for line in f:
            try:
                tasks.append(json.loads(line))
            except Exception:
                continue

    with open(OUT_JSON, "w", encoding="utf-8") as f:
        json.dump(tasks, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ Wrote tasks (array JSON): {OUT_JSON}")

    with open(OUT_CONFIG, "w", encoding="utf-8") as f:
        f.write(build_ls_config_xml())
    print(f"âš™ï¸  Wrote LS config: {OUT_CONFIG}")

    total_elapsed = time.time() - start_time
    print(f"âœ… å®Œæˆï¼šå¤„ç† {processed}/{n} æ¡ï¼ˆæ€»æ ·æœ¬ {total}ï¼‰| æ€»è€—æ—¶ {total_elapsed/60:.1f} åˆ†é’Ÿ | å¹¶å‘ {CONCURRENCY}")


if __name__ == "__main__":
    main()
